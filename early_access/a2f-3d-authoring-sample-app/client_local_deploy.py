#!/usr/bin/env python3
################################################################################
# Copyright (c) 2024, NVIDIA CORPORATION.  All rights reserved.
# NVIDIA Corporation and its licensors retain all intellectual property
# and proprietary rights in and to this software, related documentation
# and any modifications thereto.  Any use, reproduction, disclosure or
# distribution of this software and related documentation without an express
# license agreement from NVIDIA Corporation is strictly prohibited.
################################################################################
"""
Performs health checks, data captures, and latency computations for the Authoring service.

Commands:
- health_check: Checks the health of the service at the specified URL.
- data_capture: Performs sequential data exchange with the service and saves the resulting
                blendshapes to a file.
- latency: Computes latency data for the service and saves the results to a file.
"""

import argparse

import grpc
import scipy

from common import (
    check_health,
    get_avatar_face_pose,
    make_face_pose_request,
    perform_parallel_data_exchange,
    positive_int,
    upload_audio_clip_and_get_hash,
    GrpcChannelParams,
    EMOTION_KEYS,
    TIME_1_FRAME,
)

from nvidia_ace.services.a2f_authoring.v1_pb2_grpc import A2FAuthoringServiceStub

PERF_DATA_FILE = "output_perf.txt"
OUT_IMG = "output_latency.png"
OUTPUT_BLENDSHAPE = "output_blendshape.csv"
OUTPUT_EMOTIONS = "output_emotions.csv"
ALLOWED_DIFF = 0.01


def create_parser():
    """
    Creates and returns an ArgumentParser object for a GRPC client tool with
    three subcommands: 'health_check', 'data_capture', and 'latency'.

    The parser allows users to perform various checks on the Authoring service,
    including checking service health, verifying data integrity, and
    evaluating performance and latency.

    Returns:
        argparse.ArgumentParser: An ArgumentParser object configured with the
        following subcommands:

        - health_check: Check the health status of the Authoring service.
            * url (str): The URL of the Authoring service.

        - data_capture: Capture data of generated by the Authoring service.
            * url (str): The URL of the Authoring service.
            * audio_clip (str): Path to the audio clip file for generating blendshape
                data
            * print_bs_names (bool): If true, the command will print out the blendshape names.

        - latency: Check the latency of the Authoring service.
            * url (str): The URL of the Authoring service.
            * audio_clip (str): Path to the audio clip file for testing.
            * number_requests (int): The number of requests to simulate.
            * concurrent (int): The number of concurrent requests to run.
            * print_bs_names (bool): If true, the command will print out the blendshape names.

    """
    parser = argparse.ArgumentParser(description="GRPC client tool")
    subparsers = parser.add_subparsers(dest="command", required=True)

    # Health check subparser
    health_check_parser = subparsers.add_parser("health_check", help="Check GRPC service health")
    health_check_parser.add_argument("--url", type=str, required=True, help="GRPC service URL")

    # Data capture check subparser
    data_capture_parser = subparsers.add_parser("data_capture", help="Check data integrity of GRPC service")
    data_capture_parser.add_argument("--url", type=str, required=True, help="GRPC service URL")
    data_capture_parser.add_argument("--audio-clip", type=str, required=True, help="Path to audio clip file")
    data_capture_parser.add_argument(
        "--print-bs-names",
        action="store_true",
        required=False,
        help="Optional. If enabled, the command will print out the names of the returned blendshapes.",
    )

    # Latency check subparser
    latency_parser = subparsers.add_parser("latency", help="Check latency of GRPC service")
    latency_parser.add_argument("--url", type=str, required=True, help="GRPC service URL")
    latency_parser.add_argument("--audio-clip", type=str, required=True, help="Path to audio clip file")
    latency_parser.add_argument(
        "--number-requests", type=positive_int, required=True, help="Number of requests to simulate"
    )
    latency_parser.add_argument("--concurrent", type=positive_int, required=True, help="Number of concurrent requests")
    latency_parser.add_argument(
        "--print-bs-names",
        action="store_true",
        required=False,
        help="Optional. If enabled, the command will print out the names of the returned blendshapes.",
    )

    return parser


def perform_sequential_data_exchange_outputing_result_list(url: str, audio_clip: str) -> tuple[list, list]:
    """
    Performs sequential data exchange with the server, outputting a list of results.

    Args:
      url (str): The URL of the Authoring server.
      audio_clip (str): The path to the audio clip.

    Returns:
      tuple[list, list]: A list of BlendShapeData and a list of blendshape names. The orders match.

    Notes:
    This function uploads the audio clip to the server, retrieves the hash,
    and then makes sequential FacePoseRequests to the server for each frame of the audio clip.

    """
    samplerate, data = scipy.io.wavfile.read(audio_clip)
    number_frames = int((len(data) / samplerate) * 30)

    # Create a gRPC channel and stub for the service.
    channel = grpc.insecure_channel(url)
    stub = A2FAuthoringServiceStub(channel)
    (hash_gotten, bs_names) = upload_audio_clip_and_get_hash(stub, audio_clip)
    print("Perform sequential requests for the full audio clip...")
    req_list = [make_face_pose_request(hash_gotten, i * TIME_1_FRAME, bs_names) for i in range(number_frames)]
    bs_list = [get_avatar_face_pose(stub, elm) for elm in req_list]
    print("")
    return (bs_list, bs_names)


def main():
    """
    Parses the command-line arguments and executes the corresponding command.

    Commands:
    - health_check: Checks the health of the service at the specified URL.
    - data_capture: Performs sequential data exchange with the service and saves the results to a
        CSV file.
    - latency: Computes latency data for the service and saves the results to a file.
    """
    parser = create_parser()
    args = parser.parse_args()

    if args.command == "health_check":
        # Checks the health of the service at the specified URL.
        # Prints "ONLINE" if the service is available, "OFFLINE" otherwise.
        print(f'Service {args.url} is {"ONLINE" if (check_health(grpc.insecure_channel(args.url))) else "OFFLINE"}')

    elif args.command == "data_capture":
        # Performs sequential data exchange with the service and saves the results to a file.
        # Saves the blendshape data to a CSV file named OUTPUT_FILE.
        (blendshape_data_list, blendshape_names) = perform_sequential_data_exchange_outputing_result_list(
            args.url, args.audio_clip
        )
        if args.print_bs_names:
            print(f"Blendshape names are: {blendshape_names}")
        with open(OUTPUT_BLENDSHAPE, "w", encoding="utf-8") as file_out:
            file_out.write("timecode," + ",".join(blendshape_names))
            file_out.write("\n")
            for i, blendshape_data in enumerate(blendshape_data_list):
                file_out.write(str(i * TIME_1_FRAME) + "," + ",".join(list(map(str, blendshape_data.blendshapes))))
                file_out.write("\n")
        print(f"Saved results to {OUTPUT_BLENDSHAPE}")
        with open(OUTPUT_EMOTIONS, "w", encoding="utf-8") as file_out:
            file_out.write("timecode," + ",".join(EMOTION_KEYS))
            file_out.write("\n")
            for i, blendshape_data in enumerate(blendshape_data_list):
                file_out.write(
                    str(i * TIME_1_FRAME)
                    + ","
                    + ",".join([str(blendshape_data.emotions[emotion]) for emotion in EMOTION_KEYS])
                )
                file_out.write("\n")
        print(f"Saved results to {OUTPUT_EMOTIONS}")

    elif args.command == "latency":
        # Computes latency data for the service and saves the results to a file.
        # Saves the latency data to a file named PERF_DATA_FILE and plots the data to an image
        # file named OUT_IMG.
        print(f"Computing data for {args.number_requests} requests with concurrency of " f"{args.concurrent}")

        channel_params = GrpcChannelParams(True, args.url)
        results = perform_parallel_data_exchange(args.audio_clip, args.number_requests, args.concurrent, channel_params)

        print()
        if args.print_bs_names:
            print(f"Blendshape names are: {results.blendshape_names}")
        with open(PERF_DATA_FILE, "w", encoding="utf-8") as file_perf_out:
            file_perf_out.write(str(results))
        results.plot_percentiles(OUT_IMG)
        print(f"Saved latency data in {PERF_DATA_FILE}")
        print(f"Plotted latency data in {OUT_IMG}")


if __name__ == "__main__":
    main()
